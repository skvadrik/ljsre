%{

#include <stddef.h> // NULL

#include "debug_parser.h"
#include "parser.h"

bool Parser::parse (TokenArray & tok_arr, NFA<slab_allocator<> > & nfa, slab_allocator<> & allocator)
{
    StackSemantics semantics;

#   define LALR2C_R_TOKEN_TYPE             tok_arr.start[tok_arr.index].type
#   define LALR2C_R_TOKEN_SEMANTICS        tok_arr.start[tok_arr.index].value

#   define LALR2C_RW_STACK_STATE(n)        (stack_top - n)->state
#   define LALR2C_RW_STACK_SEMANTICS(n)    (stack_top - n)->semantics

#   define LALR2C_E_SHIFT_TOKEN()          do { ++ tok_arr.index; } while (0)
#   define LALR2C_E_RESERVE_STACK()        do { ++ stack_top; } while (0)
#   define LALR2C_E_POP_STACK(n)           do { stack_top -= n; } while (0)

#   define LALR2C_RW_TMP_SEMANTICS         semantics

#   define LALR2C_RW_IS_1ST_CALL           is_start

%}

%token    T_ALT
%token    T_ASSERT_START
%token    T_ASSERT_END
%token    T_ASSERT_WORD
%token    T_ASSERT_FOLLOW
%token    T_BACKREF
%token    T_CLASS
%token    T_CLASS_END
%token    T_CLASS_START
%token    T_COMMA
%token    T_COUNT
%token    T_DASH
%token    T_DOT
%token    T_LBRACE_CAPTURE
%token    T_LBRACE_LAZY
%token    T_ONE_MANY
%token    T_RBRACE
%token    T_RUNE
%token    T_ZERO_MANY
%token    T_ZERO_ONE

%fail     { return false; }

%start    pattern
%stop     T_LAMBDA

%%

class_ranges
: {
    $$.token.rune_vector = allocator.allocate_type<RuneVector> ();
    new ($$.token.rune_vector) RuneVector (allocator);
}
| class_ranges T_RUNE {
    $1.token.rune_vector->push_back ($2.token.rune);
    $$ = $1;
}
| class_ranges T_CLASS {
    for (unsigned int i = 0; i < $2.token.rune_vector->size (); ++i)
        $1.token.rune_vector->push_back ((* $2.token.rune_vector)[i]);
    $$ = $1;
}
| class_ranges T_RUNE T_DASH T_RUNE {
    const Rune r1 = $2.token.rune;
    const Rune r2 = $4.token.rune;
    const Rune r = r2 << 16 | r1;
    $1.token.rune_vector->push_back (r);
    $$ = $1;
}
;

class_body
: class_ranges    /* empty */
| class_ranges T_DASH {
    const Rune r = '-';
    $1.token.rune_vector->push_back (r);
    $$ = $1;
}
| T_DASH class_ranges {
    const Rune r = '-';
    $2.token.rune_vector->push_back (r);
    $$ = $2;
}
| T_DASH class_ranges T_DASH {
    const Rune r = '-';
    $2.token.rune_vector->push_back (r);
    $$ = $2;
}
;

class
: T_CLASS_START class_body T_CLASS_END {
    nfa.bind_rune_class ($$.frag, $2.token.rune_vector, $1.token.boolean);
}
;

atom
: T_RUNE {
    nfa.bind_rune ($$.frag, $1.token.rune);
}
| T_BACKREF {
    nfa.bind_backref ($$.frag, $1.token.backref);
}
| T_DOT {
    nfa.bind_any ($$.frag);
}
| class /* empty */
| T_CLASS {
    nfa.bind_rune_class ($$.frag, $1.token.rune_vector, true);
}
| T_LBRACE_CAPTURE disjunction T_RBRACE {
    nfa.bind_capture ($$.frag, $2.frag);
}
| T_LBRACE_LAZY disjunction T_RBRACE {
    $$ = $2;
}
;

assertion
: T_ASSERT_START {
    nfa.bind_assert_start ($$.frag);
}
| T_ASSERT_END {
    nfa.bind_assert_end ($$.frag);
}
| T_ASSERT_WORD {
    nfa.bind_assert_word ($$.frag, $1.token.boolean);
}
| T_ASSERT_FOLLOW disjunction T_RBRACE {
    nfa.bind_assert_follow ($$.frag, $2.frag, $1.token.boolean);
}
;

term
: assertion    /* empty */
| atom    /* empty */

/* "e*|e*?" */
| atom T_ZERO_MANY {
    nfa.bind_zero_many ($$.frag, $1.frag);
}
| atom T_ZERO_MANY T_ZERO_ONE {
    nfa.bind_zero_many_lazy ($$.frag, $1.frag);
}

/* "e+"/"e+?" */
| atom T_ONE_MANY {
    nfa.bind_one_many ($$.frag, $1.frag);
}
| atom T_ONE_MANY T_ZERO_ONE {
    nfa.bind_one_many_lazy ($$.frag, $1.frag);
}

/* "e?"/"e??" */
| atom T_ZERO_ONE {
    nfa.bind_zero_one ($$.frag, $1.frag);
}
| atom T_ZERO_ONE T_ZERO_ONE {
    nfa.bind_zero_one_lazy ($$.frag, $1.frag);
}

/* "e{n}"/"e{n}?" */
| atom T_COUNT {
    nfa.bind_times_eq ($$.frag, $1.frag, $2.token.count);
}
| atom T_COUNT T_ZERO_ONE {
    nfa.bind_times_eq_lazy ($$.frag, $1.frag, $2.token.count);
}

/* "e{n,}"/"e{n,}?" */
| atom T_COUNT T_COMMA {
    nfa.bind_times_gteq ($$.frag, $1.frag, $2.token.count);
}
| atom T_COUNT T_COMMA T_ZERO_ONE {
    nfa.bind_times_gteq_lazy ($$.frag, $1.frag, $2.token.count);
}

/* "e{n,m}"/"e{n,m}?" */
| atom T_COUNT T_COMMA T_COUNT {
    nfa.bind_times_gteq_lteq ($$.frag, $1.frag, $2.token.count, $4.token.count);
}
| atom T_COUNT T_COMMA T_COUNT T_ZERO_ONE {
    nfa.bind_times_gteq_lteq_lazy ($$.frag, $1.frag, $2.token.count, $4.token.count);
}
;

alternative
: term    /* empty */
| alternative term {
    nfa.bind_cat ($$.frag, $1.frag, $2.frag);
}
;

disjunction
: /* empty */ {
    nfa.bind_empty ($$.frag);
}
| alternative    /* empty */
| alternative T_ALT disjunction {
    nfa.bind_alt ($$.frag, $1.frag, $3.frag);
}
| T_ALT disjunction {
    Frag f_empty;
    nfa.bind_empty (f_empty);
    nfa.bind_alt ($$.frag, f_empty, $2.frag);
}
;

pattern
: disjunction {
    nfa.bind_match ($1.frag);
    return true;
}
;


%{
    ;

#   undef LALR2C_R_TOKEN_TYPE
#   undef LALR2C_R_TOKEN_SEMANTICS

#   undef LALR2C_RW_STACK_STATE
#   undef LALR2C_RW_STACK_SEMANTICS

#   undef LALR2C_E_SHIFT_TOKEN
#   undef LALR2C_E_RESERVE_STACK
#   undef LALR2C_E_POP_STACK

#   undef LALR2C_RW_TMP_SEMANTICS

#   undef LALR2C_RW_IS_1ST_CALL

}

%}
